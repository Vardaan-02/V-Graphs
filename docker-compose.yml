version: '3.8'
services:
  spring-backend:
    build:
      context: ./spring-service/backend
      dockerfile: Dockerfile
    container_name: workflow-spring-backend
    ports:
      - "2706:2706"
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://db:5432/dbname
      - SPRING_DATASOURCE_USERNAME=user
      - SPRING_DATASOURCE_PASSWORD=${POSTGRES_PASSWORD}

      - SPRING_DATA_REDIS_URL=redis://redis:6379

      - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:29092

      - JWT_SECRET=${JWT_SECRET:-my-super-secret-jwt-key-1234567890}
      - JWT_EXPIRATION=604800000

      - SPRING_MAIL_HOST=smtp.gmail.com
      - SPRING_MAIL_PORT=587
      - SPRING_MAIL_USERNAME=${SPRING_MAIL_USERNAME:-marcellapearl0627@gmail.com}
      - SPRING_MAIL_PASSWORD=${SPRING_MAIL_PASSWORD}
      - APP_MAIL_FROM=${SPRING_MAIL_USERNAME:-marcellapearl0627@gmail.com}

      - LOGGING_LEVEL_COM_MARCELLA_BACKEND=INFO
      - LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_KAFKA=WARN

      - SPRING_PROFILES_ACTIVE=docker

    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    networks:
      - workflow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2706/api/v1/workflows"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  fastapi-node-executor:
    build:
      context: ./new-service
      dockerfile: Dockerfile
    container_name: workflow-fastapi-executor
    ports:
      - "8000:8000"
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_GROUP_ID=fastapi-node-executor
      - KAFKA_NODE_EXECUTION_TOPIC=fastapi-nodes
      - KAFKA_NODE_COMPLETION_TOPIC=node-completion
      - KAFKA_AUTO_OFFSET_RESET=earliest

      - REDIS_URL=redis://redis:6379
      - REDIS_DB=0
      - REDIS_MAX_CONNECTIONS=20

      - SERPAPI_KEY=${SERPAPI_KEY}
      - MAX_TOKENS=100
      - TEMPERATURE=0.7

      - SERVICE_NAME=fastapi-node-executor
      - LOG_LEVEL=INFO

    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - workflow-network
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import requests; requests.get('http://localhost:8000/health')\""]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kafka:
    image: bitnami/kafka:latest
    container_name: workflow-kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093

      - KAFKA_CFG_LISTENERS=PLAINTEXT://:29092,EXTERNAL://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1
      - KAFKA_CFG_NUM_PARTITIONS=3

      - KAFKA_CFG_LOG_RETENTION_HOURS=24
      - KAFKA_CFG_LOG_RETENTION_BYTES=1073741824
      - KAFKA_CFG_LOG_SEGMENT_BYTES=67108864
      - KAFKA_CFG_LOG_CLEANUP_POLICY=delete

      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_SECURITY_PROTOCOL=PLAINTEXT

      - KAFKA_HEAP_OPTS=-Xmx1G -Xms1G

    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - workflow-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:29092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: workflow-redis
    ports:
      - "6379:6379"
    command: >
      redis-server 
      --appendonly yes 
      --appendfsync everysec
      --maxmemory 2gb 
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 60
      --timeout 0
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    networks:
      - workflow-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    sysctls:
      - net.core.somaxconn=65535
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  db:
    image: postgres:15
    container_name: workflow-postgres
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: dbname
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U user -d dbname" ]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - workflow-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: workflow-kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=workflow-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
      - KAFKA_CLUSTERS_0_METRICS_PORT=9997
      - DYNAMIC_CONFIG_ENABLED=true
      - LOGGING_LEVEL_ROOT=INFO
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - workflow-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: workflow-redis-commander
    ports:
      - "8081:8081"
    environment:
      - REDIS_HOSTS=workflow-redis:redis:6379
      - HTTP_USER=admin
      - HTTP_PASSWORD=${REDIS_COMMANDER_PASSWORD}
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - workflow-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:alpine
    container_name: workflow-nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certbot/www:/var/www/certbot:ro
      - ./certbot/conf:/etc/letsencrypt:ro
    depends_on:
      - spring-backend
      - fastapi-node-executor
    networks:
      - workflow-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  certbot:
    image: certbot/certbot
    container_name: workflow-certbot
    volumes:
      - ./certbot/www:/var/www/certbot
      - ./certbot/conf:/etc/letsencrypt
    entrypoint: "/bin/sh"
    command: -c "sleep infinity"
    networks:
      - workflow-network

volumes:
  kafka_data:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local

networks:
  workflow-network:
    name: workflow-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1